{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3afcd4d",
   "metadata": {},
   "source": [
    "# Importing the data set\n",
    "\n",
    "The data set consists of the following two columns.\n",
    "\n",
    " •  EMOTION lists the emotions.\n",
    "\n",
    " •  TEXT features the number of corresponding sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57091349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Unnamed: 2\n",
       "0      joy  On days when I feel close to my partner and ot...        NaN\n",
       "1     fear  Every time I imagine that someone I love or I ...        NaN\n",
       "2    anger  When I had been obviously unjustly treated and...        NaN\n",
       "3  sadness  When I think about the short time that we live...        NaN\n",
       "4  disgust  At a gathering I found myself involuntarily si...        NaN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv('ISEAR.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0596e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>On days when I feel close to my partner and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>Every time I imagine that someone I love or I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>When I had been obviously unjustly treated and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>When I think about the short time that we live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>At a gathering I found myself involuntarily si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMOTION                                               TEXT\n",
       "0      joy  On days when I feel close to my partner and ot...\n",
       "1     fear  Every time I imagine that someone I love or I ...\n",
       "2    anger  When I had been obviously unjustly treated and...\n",
       "3  sadness  When I think about the short time that we live...\n",
       "4  disgust  At a gathering I found myself involuntarily si..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = ['EMOTION', 'TEXT', 'Unnamed']\n",
    "data = data.drop(columns=['Unnamed'])\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bcfa736",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing\n",
    "\n",
    "Data cleaning is important to obtain better features and accuracy. We can achieve this by doing text preprocessing steps on the data.\n",
    "\n",
    "The preprocessing steps are as follows.\n",
    "\n",
    "1. Lowercase\n",
    "\n",
    "2. Remove special characters\n",
    "\n",
    "3. Remove punctuation\n",
    "\n",
    "4. Remove stop words\n",
    "\n",
    "5. Correct spelling\n",
    "\n",
    "6. Normalization\n",
    "\n",
    "The following are the libraries to preprocess the text. NLTK is a predominant free source Python package for text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e69279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries for building Emotion Classifier \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import string\n",
    "\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from textblob import Word\n",
    "\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction. text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import sklearn.feature_extraction.text as text\n",
    "\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation,TruncatedSVD\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model,naive_bayes, metrics, svm\n",
    "\n",
    "import xgboost\n",
    "\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, numpy, textblob, string\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47ab9220",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert uppercase letters to lowercase.\n",
    "data['TEXT'] = data['TEXT'].apply(lambda a: \" \".join(a.lower() for a in a.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d0b2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove white space and special characters.\n",
    "data['TEXT'] = data['TEXT'].apply(lambda a: \" \".join(a.replace('[^\\w\\s]','') for a in a.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ab4784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the stop words.\n",
    "stop = stopwords.words('english')\n",
    "data['TEXT'] = data['TEXT'].apply(lambda a: \" \".join(a for a in a.split() if a not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "945d01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct Spelling\n",
    "data['TEXT'] = data['TEXT'].apply(lambda a: str(TextBlob(a).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0183fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do Stemming\n",
    "st = PorterStemmer()\n",
    "data['TEXT'] = data['TEXT'].apply(lambda a: \" \".join([st.stem (word) for word in a.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b92fb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "data['TEXT'] = data['TEXT'].apply(lambda a: \" \".join(spell.correction(word) if spell.correction(word) is not None else word for word in a.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da7ca9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMOTION</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "      <td>day feel close partner friends feel peace also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fear</td>\n",
       "      <td>ever time imagine someone love could contact s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anger</td>\n",
       "      <td>obvious unjustly treat possible lucid this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>think short time live relax period life think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disgust</td>\n",
       "      <td>gather found involuntarily sit next two peopl ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMOTION                                               TEXT\n",
       "0      joy  day feel close partner friends feel peace also...\n",
       "1     fear  ever time imagine someone love could contact s...\n",
       "2    anger         obvious unjustly treat possible lucid this\n",
       "3  sadness  think short time live relax period life think ...\n",
       "4  disgust  gather found involuntarily sit next two peopl ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After completing all the preprocessing steps, this is what the data looks like.\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70921f94",
   "metadata": {},
   "source": [
    "# Label Encoding\n",
    "\n",
    "The target encoding is an approach to convert categorical value to numerical value.\n",
    "There are seven categories in this data, and we must encode them to proceed further. We are using the label encoder function to encode these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4761430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMOTION\n",
       "joy        1092\n",
       "sadness    1082\n",
       "anger      1079\n",
       "fear       1076\n",
       "shame      1071\n",
       "disgust    1066\n",
       "guilt      1049\n",
       "guit          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data before encoding.\n",
    "data['EMOTION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e39e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels encode the target variable\n",
    "object = preprocessing. LabelEncoder()\n",
    "data['EMOTION'] = object. fit_transform(data['EMOTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "263f4ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EMOTION\n",
       "5    1092\n",
       "6    1082\n",
       "0    1079\n",
       "2    1076\n",
       "7    1071\n",
       "1    1066\n",
       "3    1049\n",
       "4       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data after encoding.\n",
    "data['EMOTION'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff7d277f",
   "metadata": {},
   "source": [
    "# Train-Test Split\n",
    "\n",
    "The data is split into two parts: one part trains the model, which is the training set, and the other part evaluates the model, which is the test set. The train_test_split library from sklearn.model_selection is imported to split the data frame into two parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ec8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Get the emotions with at least two instances\n",
    "valid_emotions = data['EMOTION'].value_counts()[data['EMOTION'].value_counts() > 1].index.tolist()\n",
    "\n",
    "# Filter the data to only include valid emotions\n",
    "filtered_data = data[data['EMOTION'].isin(valid_emotions)]\n",
    "\n",
    "# Split the filtered data into train and test sets\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(filtered_data['TEXT'], filtered_data['EMOTION'], stratify=filtered_data['EMOTION'], test_size=0.4, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "028caa66",
   "metadata": {},
   "source": [
    "Now that we have completed the train-test split step, the next step is to extract the features out of these texts. For this, we use two important methods.\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "Feature engineering is the process of creating a new feature considering the domain context. Let's implement the count vectorizer and TF-IDF techniques to obtain the relevant features from the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8473262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "\n",
    "cv.fit(data['TEXT'])\n",
    "\n",
    "cv_xtrain = cv.transform(Xtrain)\n",
    "\n",
    "cv_xtest = cv. transform(Xtest)\n",
    "\n",
    "# word-level TF-IDF\n",
    "\n",
    "tv = TfidfVectorizer()\n",
    "\n",
    "tv.fit(data['TEXT'])\n",
    "\n",
    "#Transform the training and validation data using TF-IDF object.\n",
    "\n",
    "tv_xtrain = tv.transform(Xtrain)\n",
    "\n",
    "tv_xtest =tv.transform(Xtest) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e831b554",
   "metadata": {},
   "source": [
    "Now let's get into one of the crucial steps to build the multiclass text classification model. We explore the different algorithms in this section.\n",
    "\n",
    "# Model Building Phase\n",
    "\n",
    "In this phase, we build different models using both count vectors and word-level TF-IDF as features, and then the model is finalized based on the accuracy level of the classifier.\n",
    "\n",
    "Let's build a classifier function so that you we play around with the different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22cb47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(model_initializer, independent_variables_training, target, independent_variable_test):\n",
    "    model_initializer.fit(independent_variables_training, target)\n",
    "    modelPred = model_initializer.predict(independent_variable_test)\n",
    "    return metrics.accuracy_score(modelPred, Ytest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4bdeacb",
   "metadata": {},
   "source": [
    "Let's use the preceding function and try various algorithms.\n",
    "\n",
    "# Multinomial Naive Bayes\n",
    "\n",
    "The multinomial naive Bayes algorithm essentially calculates the probability of each category using the Bayes theorem.\n",
    "\n",
    "Let's build a naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85e83b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5329341317365269\n",
      "0.542581503659348\n"
     ]
    }
   ],
   "source": [
    "# The following uses naive Bayes generated with count vectors.\n",
    "output = build(naive_bayes.MultinomialNB(), cv_xtrain, Ytrain, cv_xtest)\n",
    "print(output)\n",
    "# The following uses naive Bayes generated with word-level TF-IDF vectors.\n",
    "output = build (naive_bayes. MultinomialNB (), tv_xtrain, Ytrain, tv_xtest) \n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac94d0ff",
   "metadata": {},
   "source": [
    "53.2% accuracy is obtained from count vectorizer features. \n",
    "\n",
    "54.2% accuracy is obtained from TD-IDF vectorizer features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58d38db0",
   "metadata": {},
   "source": [
    "# Linear Classifier/Logistic Regression\n",
    "\n",
    "The following builds a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9e8b83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5515635395874917\n",
      "0.5671989354624085\n"
     ]
    }
   ],
   "source": [
    "# for CV\n",
    "\n",
    "output = build(linear_model.LogisticRegression(), cv_xtrain, Ytrain, cv_xtest) \n",
    "print(output)\n",
    "\n",
    "# for TF-IDF\n",
    "\n",
    "output = build(linear_model.LogisticRegression(), tv_xtrain, Ytrain,tv_xtest)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40fc0b3d",
   "metadata": {},
   "source": [
    "# Support-Vector Machine\n",
    "Let's build the SVM Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a01ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5199600798403193\n",
      "0.5582168995342648\n"
     ]
    }
   ],
   "source": [
    "#for cv\n",
    "\n",
    "output =build(svm. SVC(), cv_xtrain, Ytrain, cv_xtest)\n",
    "print (output)\n",
    "\n",
    "#for TF-IDF\n",
    "\n",
    "output =build (svm.SVC(), tv_xtrain, Ytrain, tv_xtest)\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1470068a",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "The following builds a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e35077c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5359281437125748\n",
      "0.5508982035928144\n"
     ]
    }
   ],
   "source": [
    "#for CV\n",
    "\n",
    "output = build(ensemble. RandomForestClassifier(), cv_xtrain, Ytrain, cv_xtest) \n",
    "print(output)\n",
    "\n",
    "#for TF-IDF\n",
    "\n",
    "output = build(ensemble. RandomForestClassifier(), tv_xtrain, Ytrain,tv_xtest)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ceaef5d",
   "metadata": {},
   "source": [
    "# Model Evaluation and Comparison Summary\n",
    "\n",
    "We tried a few different machine learning algorithms using both count vectorizers and TE-IDF vectorizers.Among the models mentioned, the Linear Classifier/Logistic Regression using TF-IDF vectorizer achieved the highest accuracy with 56.7%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
